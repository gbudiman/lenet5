{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "require 'nn'\n",
    "require 'optim'\n",
    "require 'mnist'\n",
    "require 'dataset-mnist'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "torch.manualSeed(0)\n",
    "torch.setnumthreads(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "--classes = { 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20 }\n",
    "classes = { 1, 2, 3, 4, 5, 6, 7, 8, 9, 10 }\n",
    "geometry = { 32, 32 }\n",
    "\n",
    "net = nn.Sequential()\n",
    "\n",
    "net:add(nn.SpatialConvolution(1, 6, 5, 5))\n",
    "net:add(nn.ReLU())\n",
    "net:add(nn.SpatialMaxPooling(2, 2, 2, 2))\n",
    "\n",
    "net:add(nn.SpatialConvolution(6, 16, 5, 5))\n",
    "net:add(nn.ReLU())\n",
    "net:add(nn.SpatialMaxPooling(2, 2, 2, 2))\n",
    "\n",
    "net:add(nn.View(16*5*5))\n",
    "net:add(nn.Linear(16*5*5, 120))\n",
    "net:add(nn.ReLU())\n",
    "net:add(nn.Linear(120, 84))\n",
    "net:add(nn.ReLU())\n",
    "net:add(nn.Linear(84, #classes))\n",
    "net:add(nn.LogSoftMax())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "parameters, gradParameters = net:getParameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "criterion = nn.ClassNLLCriterion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<mnist> done\t\n"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<mnist> done\t\n"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 1\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       "[torch.DoubleTensor of size 10]\n",
       "\n"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<mnist> done\t\n"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<mnist> done\t\n"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_training_patches = 60000--60000\n",
    "n_testing_patches = 10000--10000\n",
    "\n",
    "train_data = mnist.loadTrainSet(n_training_patches, geometry)\n",
    "train_data_inverted = mnist.loadTrainSet(n_training_patches, geometry)\n",
    "\n",
    "for i = 1, n_training_patches do\n",
    "    train_data_inverted[i][1]:apply(function(x) \n",
    "        return 255 - x\n",
    "    end)\n",
    "\n",
    "--     original = train_data_inverted[i][2]\n",
    "--     prepend = torch.zeros(10)\n",
    "--     combined = torch.cat(prepend, original)\n",
    "    --print(combined)\n",
    "    \n",
    "    --train_data_inverted.labels[i] = train_data_inverted.labels[i] + 10\n",
    "    --torch.reshape(train_data_inverted[i][2], combined, 20)\n",
    "--     train_data_inverted[i][2]:resize(20, 1)\n",
    "--     train_data_inverted[i][2][12] = 15\n",
    "--     train_data_inverted[i][2]:apply(function(x)\n",
    "--         return 5 - x\n",
    "--     end)\n",
    "end\n",
    "\n",
    "-- print(train_data_inverted[1][1])\n",
    "-- print(train_data_inverted[1][2])\n",
    "\n",
    "train_data:normalizeGlobal(mean, std)\n",
    "train_data_inverted:normalizeGlobal(mean, std)\n",
    "\n",
    "test_data = mnist.loadTestSet(n_testing_patches, geometry)\n",
    "test_data_inverted = mnist.loadTestSet(n_testing_patches, geometry)\n",
    "\n",
    "for i = 1, n_testing_patches do\n",
    "    test_data_inverted[i][1]:apply(function(x)\n",
    "            return 255 - x\n",
    "    end)\n",
    "    --test_data_inverted.data[i] = 255 - test_data_inverted.data[i]\n",
    "end\n",
    "\n",
    "test_data:normalizeGlobal(mean, std)\n",
    "test_data_inverted:normalizeGlobal(mean, std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "confusion = optim.ConfusionMatrix(classes)\n",
    "epoch_limit = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "actual_train = train_data_inverted\n",
    "actual_test = test_data_inverted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Epoch: 1\t\n"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "ConfusionMatrix:\n",
       "[[    4874       4      20      18       5      18      25     896      54       9]   82.289% \t[class: 1]\n",
       " [      23    4855      59      29       7       7      10    1666      50      36]   72.011% \t[class: 2]\n",
       " [     645      34    2965     404      87      14     174    1546      75      14]   49.765% \t[class: 3]\n",
       " [     548      41     213    3419       8     102      25    1572     122      81]   55.766% \t[class: 4]\n",
       " [     100      18      17      74    3105       0     192    2076      18     242]   53.150% \t[class: 5]\n",
       " [     680      41      97     775     102    1751     146    1321     424      84]   32.300% \t[class: 6]\n",
       " [     415      70      93     147      55      50    3416    1645      24       3]   57.722% \t[class: 7]\n",
       " [     129      76      55      31      51       7      15    5634      30     237]   89.928% \t[class: 8]\n",
       " [     476     184     174     429      46     204     123    1722    2419      74]   41.343% \t[class: 9]\n",
       " [     181      46      19     130     328       7      19    2608      66    2545]]  42.780% \t[class: 10]\n",
       " + average row correct: 57.705540955067% \n",
       " + average rowUcol correct (VOC measure): 43.568090796471% \n",
       " + global correct: 58.305%\n",
       "{\n",
       "  _mat_flat : LongTensor - size: 100\n",
       "  valids : FloatTensor - size: 10\n",
       "  mat : LongTensor - size: 10x10\n",
       "  averageUnionValid : 0.43568090796471\n",
       "  _targ_idx : LongTensor - empty\n",
       "  averageValid : 0.57705540955067\n",
       "  classes : \n",
       "    {\n",
       "      1 : 1\n",
       "      2 : 2\n",
       "      3 : 3\n",
       "      4 : 4\n",
       "      5 : 5\n",
       "      6 : 6\n",
       "      7 : 7\n",
       "      8 : 8\n",
       "      9 : 9\n",
       "      10 : 10\n",
       "    }\n",
       "  _prediction : FloatTensor - size: 10\n",
       "  _pred_idx : LongTensor - size: 1\n",
       "  nclasses : 10\n",
       "  _max : FloatTensor - size: 1\n",
       "  _target : FloatTensor - empty\n",
       "  unionvalids : FloatTensor - size: 10\n",
       "  totalValid : 0.58305\n",
       "}\n",
       "Epoch: 2\t\n"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "ConfusionMatrix:\n",
       "[[    5711       1      32       9       6      47      46       8      47      16]   96.421% \t[class: 1]\n",
       " [       1    6564      51      25       3      32       8      10      34      14]   97.360% \t[class: 2]\n",
       " [      39      40    5366     104      95      19      83      84     109      19]   90.064% \t[class: 3]\n",
       " [      31      31     153    5462       1     188      14      73     118      60]   89.088% \t[class: 4]\n",
       " [       5      20      51       1    5355       8      79      12      25     286]   91.664% \t[class: 5]\n",
       " [      63      31      31     181      50    4778      98      11     129      49]   88.139% \t[class: 6]\n",
       " [      34      29      49       0      58      92    5616       4      35       1]   94.897% \t[class: 7]\n",
       " [      18      40      76      21      51      17       0    5780      17     245]   92.259% \t[class: 8]\n",
       " [      24     111      50     163      38     157      63      20    5125     100]   87.592% \t[class: 9]\n",
       " [      42      27      22      83     257      22       5     185      90    5216]]  87.679% \t[class: 10]\n",
       " + average row correct: 91.516108512878% \n",
       " + average rowUcol correct (VOC measure): 84.505416750908% \n",
       " + global correct: 91.621666666667%\n",
       "{\n",
       "  _mat_flat : LongTensor - size: 100\n",
       "  valids : FloatTensor - size: 10\n",
       "  mat : LongTensor - size: 10x10\n",
       "  averageUnionValid : 0.84505416750908\n",
       "  _targ_idx : LongTensor - empty\n",
       "  averageValid : 0.91516108512878\n",
       "  classes : \n",
       "    {\n",
       "      1 : 1\n",
       "      2 : 2\n",
       "      3 : 3\n",
       "      4 : 4\n",
       "      5 : 5\n",
       "      6 : 6\n",
       "      7 : 7\n",
       "      8 : 8\n",
       "      9 : 9\n",
       "      10 : 10\n",
       "    }\n",
       "  _prediction : FloatTensor - size: 10\n",
       "  _pred_idx : LongTensor - size: 1\n",
       "  nclasses : 10\n",
       "  _max : FloatTensor - size: 1\n",
       "  _target : FloatTensor - empty\n",
       "  unionvalids : FloatTensor - size: 10\n",
       "  totalValid : 0.91621666666667\n",
       "}\n",
       "Epoch: 3\t\n"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "ConfusionMatrix:\n",
       "[[    5775       1      20       6       6      24      37       6      33      15]   97.501% \t[class: 1]\n",
       " [       2    6619      45      11       6       8       4      10      29       8]   98.176% \t[class: 2]\n",
       " [      25      47    5613      60      37      12      30      62      64       8]   94.209% \t[class: 3]\n",
       " [      19      12      95    5716       1     113       9      47      72      47]   93.231% \t[class: 4]\n",
       " [       5      17      26       0    5533       3      47      12      19     180]   94.711% \t[class: 5]\n",
       " [      38      16      13      84      12    5125      49       4      45      35]   94.540% \t[class: 6]\n",
       " [      28      15      17       1      36      47    5747       0      27       0]   97.111% \t[class: 7]\n",
       " [      10      23      63      26      34       7       0    5973      18     111]   95.339% \t[class: 8]\n",
       " [      22      71      38      82      24      55      54      16    5422      67]   92.668% \t[class: 9]\n",
       " [      31      19       5      68     175      22       1     103      48    5477]]  92.066% \t[class: 10]\n",
       " + average row correct: 94.955144524574% \n",
       " + average rowUcol correct (VOC measure): 90.44608771801% \n",
       " + global correct: 95%\n",
       "{\n"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "  _mat_flat : LongTensor - size: 100\n",
       "  valids : FloatTensor - size: 10\n",
       "  mat : LongTensor - size: 10x10\n",
       "  averageUnionValid : 0.9044608771801\n",
       "  _targ_idx : LongTensor - empty\n",
       "  averageValid : 0.94955144524574\n",
       "  classes : \n",
       "    {\n",
       "      1 : 1\n",
       "      2 : 2\n",
       "      3 : 3\n",
       "      4 : 4\n",
       "      5 : 5\n",
       "      6 : 6\n",
       "      7 : 7\n",
       "      8 : 8\n",
       "      9 : 9\n",
       "      10 : 10\n",
       "    }\n",
       "  _prediction : FloatTensor - size: 10\n",
       "  _pred_idx : LongTensor - size: 1\n",
       "  nclasses : 10\n",
       "  _max : FloatTensor - size: 1\n",
       "  _target : FloatTensor - empty\n",
       "  unionvalids : FloatTensor - size: 10\n",
       "  totalValid : 0.95\n",
       "}\n",
       "Epoch: 4\t\n"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "ConfusionMatrix:\n",
       "[[    5811       2      19       3       6      16      29       5      20      12]   98.109% \t[class: 1]\n",
       " [       1    6640      36      15       8       0       4       9      23       6]   98.487% \t[class: 2]\n",
       " [      20      41    5712      52      20       5      13      48      41       6]   95.871% \t[class: 3]\n",
       " [      12       7      71    5823       2      84       5      34      59      34]   94.976% \t[class: 4]\n",
       " [       4      14      15       1    5619       2      34       6      14     133]   96.183% \t[class: 5]\n",
       " [      23       8       8      49       4    5211      40       4      37      37]   96.126% \t[class: 6]\n",
       " [      24      12       8       0      23      37    5790       0      24       0]   97.837% \t[class: 7]\n",
       " [       7      18      45      18      21       7       0    6061      19      69]   96.744% \t[class: 8]\n",
       " [      22      47      32      63      17      34      38      13    5536      49]   94.616% \t[class: 9]\n",
       " [      26      14       2      57     122      25       1      82      37    5583]]  93.848% \t[class: 10]\n",
       " + average row correct: 96.279752850533% \n",
       " + average rowUcol correct (VOC measure): 92.857708930969% \n",
       " + global correct: 96.31%\n",
       "{\n",
       "  _mat_flat : LongTensor - size: 100\n",
       "  valids : FloatTensor - size: 10\n",
       "  mat : LongTensor - size: 10x10\n",
       "  averageUnionValid : 0.92857708930969\n",
       "  _targ_idx : LongTensor - empty\n",
       "  averageValid : 0.96279752850533\n",
       "  classes : \n",
       "    {\n",
       "      1 : 1\n",
       "      2 : 2\n",
       "      3 : 3\n",
       "      4 : 4\n",
       "      5 : 5\n",
       "      6 : 6\n",
       "      7 : 7\n",
       "      8 : 8\n",
       "      9 : 9\n",
       "      10 : 10\n",
       "    }\n"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "  _prediction : FloatTensor - size: 10\n",
       "  _pred_idx : LongTensor - size: 1\n",
       "  nclasses : 10\n",
       "  _max : FloatTensor - size: 1\n",
       "  _target : FloatTensor - empty\n",
       "  unionvalids : FloatTensor - size: 10\n",
       "  totalValid : 0.9631\n",
       "}\n",
       "Epoch: 5\t\n"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "ConfusionMatrix:\n",
       "[[    5831       1      16       3       6      12      24       4      15      11]   98.447% \t[class: 1]\n",
       " [       1    6651      33      13       8       0       3       9      18       6]   98.650% \t[class: 2]\n",
       " [      14      31    5777      38      12       1       9      36      33       7]   96.962% \t[class: 3]\n",
       " [      10       7      56    5878       2      66       2      28      54      28]   95.873% \t[class: 4]\n",
       " [       3      13      13       1    5658       1      23       7      11     112]   96.850% \t[class: 5]\n",
       " [      17       4       7      39       3    5249      37       5      31      29]   96.827% \t[class: 6]\n",
       " [      23      10       6       1      16      33    5809       0      20       0]   98.158% \t[class: 7]\n",
       " [       3      15      36      12      21       4       0    6099      17      58]   97.350% \t[class: 8]\n",
       " [      19      41      32      49      19      29      29      12    5578      43]   95.334% \t[class: 9]\n",
       " [      21      10       2      45     103      24       2      68      32    5642]]  94.839% \t[class: 10]\n",
       " + average row correct: 96.929215788841% \n",
       " + average rowUcol correct (VOC measure): 94.0646058321% \n",
       " + global correct: 96.953333333333%\n",
       "{\n",
       "  _mat_flat : LongTensor - size: 100\n",
       "  valids : FloatTensor - size: 10\n",
       "  mat : LongTensor - size: 10x10\n",
       "  averageUnionValid : 0.940646058321\n",
       "  _targ_idx : LongTensor - empty\n",
       "  averageValid : 0.96929215788841\n",
       "  classes : \n",
       "    {\n",
       "      1 : 1\n",
       "      2 : 2\n",
       "      3 : 3\n",
       "      4 : 4\n",
       "      5 : 5\n",
       "      6 : 6\n",
       "      7 : 7\n",
       "      8 : 8\n",
       "      9 : 9\n",
       "      10 : 10\n",
       "    }\n",
       "  _prediction : FloatTensor - size: 10\n",
       "  _pred_idx : LongTensor - size: 1\n",
       "  nclasses : 10\n",
       "  _max : FloatTensor - size: 1\n",
       "  _target : FloatTensor - empty\n",
       "  unionvalids : FloatTensor - size: 10\n",
       "  totalValid : 0.96953333333333\n",
       "}\n"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 10\n",
    "for epoch = 1, epoch_limit do\n",
    "    print(\"Epoch: \" .. epoch)\n",
    "    for t = 1, actual_train:size(), batch_size do\n",
    "        local inputs = torch.Tensor(batch_size, 1, geometry[1], geometry[2])\n",
    "        local targets = torch.Tensor(batch_size)\n",
    "        local k = 1\n",
    "\n",
    "        for i = t, math.min(t + batch_size - 1, actual_train:size()) do\n",
    "            local sample = actual_train[i]\n",
    "            local input = sample[1]:clone()\n",
    "            \n",
    "            local _, target = sample[2]:clone():max(1)\n",
    "\n",
    "            target = target:squeeze()\n",
    "            inputs[k] = input\n",
    "            targets[k] = target\n",
    "            k = k + 1\n",
    "        end\n",
    "\n",
    "        local feval = function(x)\n",
    "            collectgarbage()\n",
    "\n",
    "            if x ~= parameters then\n",
    "                parameters:copy(x)\n",
    "            end\n",
    "            gradParameters:zero()\n",
    "\n",
    "            local outputs = net:forward(inputs)\n",
    "            local f = criterion:forward(outputs, targets)\n",
    "            local df_do = criterion:backward(outputs, targets)\n",
    "            net:backward(inputs, df_do)\n",
    "\n",
    "            for i = 1, batch_size do\n",
    "                confusion:add(outputs[i], targets[i])\n",
    "            end\n",
    "\n",
    "            return f, gradParameters\n",
    "        end\n",
    "\n",
    "        sgd_state = sgd_state or {\n",
    "            learning_rate = 0.06,\n",
    "            momentum = 0,\n",
    "            learning_rate_decay = 5e-7\n",
    "        }\n",
    "        optim.sgd(feval, parameters, sgd_state)\n",
    "\n",
    "    end\n",
    "    \n",
    "    print(confusion)\n",
    "    confusion:zero()\n",
    "end\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConfusionMatrix:\n",
       "[[     974       0       1       0       0       1       0       1       3       0]   99.388% \t[class: 1]\n",
       " [       0    1131       2       0       0       1       0       0       1       0]   99.648% \t[class: 2]\n",
       " [       5      11     998      10       1       0       0       3       4       0]   96.705% \t[class: 3]\n",
       " [       1       0       1     998       0       2       0       4       2       2]   98.812% \t[class: 4]\n",
       " [       0       1       3       0     961       0       1       0       2      14]   97.862% \t[class: 5]\n",
       " [       3       1       0      12       2     870       1       0       1       2]   97.534% \t[class: 6]\n",
       " [      15       4       1       1       8      38     885       0       6       0]   92.380% \t[class: 7]\n",
       " [       0       7      13       4       1       2       0     989       1      11]   96.206% \t[class: 8]\n",
       " [       6       4       3      30       3       6       2       4     901      15]   92.505% \t[class: 9]\n",
       " [       5       7       0       5      12       1       0       4       1     974]]  96.531% \t[class: 10]\n",
       " + average row correct: 96.757030487061% \n",
       " + average rowUcol correct (VOC measure): 93.75114440918% \n",
       " + global correct: 96.81%\n",
       "{\n",
       "  _mat_flat : LongTensor - size: 100\n",
       "  valids : FloatTensor - size: 10\n",
       "  mat : LongTensor - size: 10x10\n",
       "  averageUnionValid : 0.9375114440918\n",
       "  _targ_idx : LongTensor - empty\n",
       "  averageValid : 0.96757030487061\n",
       "  classes : \n",
       "    {\n",
       "      1 : 1\n",
       "      2 : 2\n",
       "      3 : 3\n",
       "      4 : 4\n",
       "      5 : 5\n",
       "      6 : 6\n",
       "      7 : 7\n",
       "      8 : 8\n",
       "      9 : 9\n",
       "      10 : 10\n",
       "    }\n",
       "  _prediction : FloatTensor - size: 10\n",
       "  _pred_idx : LongTensor - size: 1\n",
       "  nclasses : 10\n",
       "  _max : FloatTensor - size: 1\n",
       "  _target : FloatTensor - empty\n",
       "  unionvalids : FloatTensor - size: 10\n",
       "  totalValid : 0.9681\n",
       "}\n"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion:zero()\n",
    "\n",
    "for t = 1, actual_test:size(), 10 do\n",
    "    local inputs = torch.Tensor(batch_size, 1, geometry[1], geometry[2])\n",
    "    local targets = torch.Tensor(batch_size)\n",
    "    local k = 1\n",
    "    \n",
    "    for i = t, math.min(t + batch_size - 1, actual_test:size()) do\n",
    "        local sample = actual_test[i]\n",
    "        local input = sample[1]:clone()\n",
    "        local _, target = sample[2]:clone():max(1)\n",
    "        target = target:squeeze()\n",
    "        inputs[k] = input\n",
    "        targets[k] = target\n",
    "        k = k + 1\n",
    "    end\n",
    "    \n",
    "    local preds = net:forward(inputs)\n",
    "    \n",
    "    for i = 1, batch_size do\n",
    "        confusion:add(preds[i], targets[i])\n",
    "    end\n",
    "end\n",
    "\n",
    "print(confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "iTorch",
   "language": "lua",
   "name": "itorch"
  },
  "language_info": {
   "name": "lua",
   "version": "5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
