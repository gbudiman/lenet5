{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "require 'nn'\n",
    "require 'optim'\n",
    "\n",
    "torch.manualSeed(0)\n",
    "torch.setnumthreads(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "function setup() \n",
    "    classes = { 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11 }\n",
    "    geometry = { 32, 32 }\n",
    "\n",
    "    net = nn.Sequential()\n",
    "\n",
    "    net:add(nn.SpatialConvolution(3, 6, 5, 5))\n",
    "    net:add(nn.ReLU())\n",
    "    net:add(nn.SpatialMaxPooling(2, 2, 2, 2))\n",
    "\n",
    "    net:add(nn.SpatialConvolution(6, 16, 5, 5))\n",
    "    net:add(nn.ReLU())\n",
    "    net:add(nn.SpatialMaxPooling(2, 2, 2, 2))\n",
    "\n",
    "    net:add(nn.View(16*5*5))\n",
    "    net:add(nn.Linear(16*5*5, 120))\n",
    "    net:add(nn.ReLU())\n",
    "    net:add(nn.Linear(120, 84))\n",
    "    net:add(nn.ReLU())\n",
    "    net:add(nn.Linear(84, #classes))\n",
    "    net:add(nn.LogSoftMax())\n",
    "    \n",
    "    parameters, gradParameters = net:getParameters()\n",
    "    criterion = nn.ClassNLLCriterion()\n",
    "    confusion = optim.ConfusionMatrix(classes)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "function normalize(input, n_channels)\n",
    "    local mean = {}\n",
    "    local stdev = {}\n",
    "    \n",
    "    for channel = 1, n_channels do\n",
    "        mean[channel] = input.data[{ {}, {channel}, {}, {} }]:mean()\n",
    "        stdev[channel] = input.data[{ {}, {channel}, {}, {} }]:std()\n",
    "        \n",
    "        print('Channel ' .. channel .. ' mean: ' .. mean[channel] .. ' stdev: ' .. stdev[channel])\n",
    "        \n",
    "        input.data[{ {}, {channel}, {}, {} }]:add(-mean[channel])\n",
    "        input.data[{ {}, {channel}, {}, {} }]:div(stdev[channel])\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "function load_data()    \n",
    "    train = torch.load('mnist-p2b-train.t7')\n",
    "    test = torch.load('mnist-p2b-test.t7')\n",
    "    \n",
    "    n_train = train.data:size()[1]\n",
    "    n_test = test.data:size()[1]\n",
    "    \n",
    "    train.data = train.data:double()\n",
    "    test.data = test.data:double()\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "function exec_training(obj, n_channels, current_epoch) \n",
    "    confusion:zero()\n",
    "    \n",
    "    for t = 1, n_train, batch_size do\n",
    "        local limit = math.min(t + batch_size - 1, n_train)\n",
    "        \n",
    "        local limited_batch_size = limit - t + 1\n",
    "        local inputs = torch.Tensor(limited_batch_size, n_channels, geometry[1], geometry[2])\n",
    "        local targets = torch.Tensor(limited_batch_size)\n",
    "        local k = 1\n",
    "        \n",
    "        for i = t, limit do\n",
    "            local input = obj.data[i]:clone()\n",
    "            local target = obj.label[i]\n",
    "            \n",
    "            inputs[k] = input\n",
    "            targets[k] = target\n",
    "            k = k + 1\n",
    "        end\n",
    "        \n",
    "        local feval = function(x)\n",
    "            collectgarbage()\n",
    "            \n",
    "            if x ~= parameters then\n",
    "                parameters:copy(x)\n",
    "            end\n",
    "            gradParameters:zero()\n",
    "            \n",
    "            local outputs = net:forward(inputs)\n",
    "            local f = criterion:forward(outputs, targets)\n",
    "            local df_do = criterion:backward(outputs, targets)\n",
    "            net:backward(inputs, df_do)\n",
    "            \n",
    "            for i = 1, limited_batch_size do\n",
    "                confusion:add(outputs[i], targets[i])\n",
    "            end\n",
    "            \n",
    "            return f, gradParameters\n",
    "        end\n",
    "        \n",
    "        sgd_state = sgd_state or {\n",
    "            learningRate = 0.03,\n",
    "            learningRateDecay = 1e-7,\n",
    "            momentum = 0.5\n",
    "        }\n",
    "        optim.sgd(feval, parameters, sgd_state)\n",
    "    end\n",
    "    \n",
    "    confusion:updateValids()\n",
    "    return confusion.averageValid\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "function exec_testing(obj, n_channels, current_epoch)\n",
    "    confusion:zero()\n",
    "    \n",
    "    for t = 1, n_test, batch_size do\n",
    "        local limit = math.min(t + batch_size - 1, n_test)\n",
    "        \n",
    "        local limited_batch_size = limit - t + 1\n",
    "        local inputs = torch.Tensor(limited_batch_size, n_channels, geometry[1], geometry[2])\n",
    "        local targets = torch.Tensor(limited_batch_size)\n",
    "        local k = 1\n",
    "        \n",
    "        for i = t, limit do\n",
    "            local input = obj.data[i]:clone()\n",
    "            local target = obj.label[i]\n",
    "            \n",
    "            inputs[k] = input\n",
    "            targets[k] = target\n",
    "            k = k + 1\n",
    "        end\n",
    "        \n",
    "        local preds = net:forward(inputs)\n",
    "        \n",
    "        for i = 1, limited_batch_size do\n",
    "            confusion:add(preds[i], targets[i])\n",
    "        end\n",
    "    end \n",
    "    \n",
    "    confusion:updateValids()\n",
    "    return confusion.averageValid\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "setup()\n",
    "load_data()\n",
    "normalize(train, 3)\n",
    "normalize(test, 3)\n",
    "\n",
    "n_epoch = 256\n",
    "batch_size = 256\n",
    "local last_train_conf\n",
    "local last_test_conf\n",
    "for epoch = 1, n_epoch do\n",
    "    local acc_train = exec_training(train, 3, epoch)\n",
    "    \n",
    "    if (epoch == n_epoch) then\n",
    "        last_train_conf = confusion:__tostring__()\n",
    "    end\n",
    "    \n",
    "    local acc_test = exec_testing(test, 3, epoch)\n",
    "    \n",
    "    if (epoch == n_epoch) then\n",
    "        last_test_conf = confusion:__tostring__()\n",
    "    end\n",
    "    \n",
    "    io.write(string.format('Epoch %3d: %.4f%% | %.4f%%\\n', epoch, acc_train * 100, acc_test * 100))\n",
    "end\n",
    "\n",
    "print(last_train_conf)\n",
    "print(last_test_conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "iTorch",
   "language": "lua",
   "name": "itorch"
  },
  "language_info": {
   "name": "lua",
   "version": "5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
